{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Dados\n",
    "\n",
    "Nesta seção, dados de mensagens de usuários em um fórum específico são extraídos, organizados e salvos em arquivos CSV. Utilizamos a biblioteca `requests` para acessar a página e `BeautifulSoup` para análise de HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_posts(url, output_dir=\"csv/general autism discussion\"):\n",
    "    request = requests.get(url)\n",
    "    content = request.content\n",
    "\n",
    "    site = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    posts = site.findAll('div', attrs={'class': 'message-col'})\n",
    "\n",
    "    user_names = []\n",
    "    genders = []\n",
    "    messages = []\n",
    "\n",
    "    for post in posts:\n",
    "        # Lógica de extração de usuário e gênero\n",
    "        user = post.find_previous_sibling('div', attrs={'class': 'user-col'})\n",
    "        if user:\n",
    "            user_name = user.find('a', href=True)\n",
    "            if user_name:\n",
    "                user_name = user_name.text.strip()\n",
    "                user_names.append(user_name)\n",
    "\n",
    "            gender = user.find(string=lambda string: string and 'Gender:' in string)\n",
    "            if gender:\n",
    "                gender = gender.split('Gender:')[1].strip()\n",
    "                genders.append(gender)\n",
    "            else:\n",
    "                genders.append(None)\n",
    "\n",
    "        message_content = post.find('div', attrs={'class': 'message-content'})\n",
    "        if message_content:\n",
    "            messages.append(message_content.text.strip())\n",
    "        else:\n",
    "            messages.append(None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Nome do Usuário': user_names,\n",
    "        'Gênero': genders,\n",
    "        'Conteúdo da Mensagem': messages\n",
    "    })\n",
    "\n",
    "    title = site.find('title').text.strip().replace(\" \", \"\").replace(\"|\", \"\").replace(\":\", \"\")\n",
    "    title = title.replace(\"Asperger's_&_Autism_Community_-_Wrong_Planet\", \"\").strip(\"_\")\n",
    "    title = re.sub(r'[\\\\/*?:\"<>|]', \"\", title)\n",
    "    file_name = f\"{title}.csv\"\n",
    "    full_name_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    df.to_csv(full_name_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "    \"https://wrongplanet.net/forums/viewtopic.php?t=28967\", \n",
    "    \"https://wrongplanet.net/forums/viewtopic.php?t=306110\", \n",
    "    \"https://wrongplanet.net/forums/viewtopic.php?t=415040\", \n",
    "    \"https://wrongplanet.net/forums/viewtopic.php?t=422455\"\n",
    "]\n",
    "\n",
    "for link in links:\n",
    "    extract_and_save_posts(link)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
